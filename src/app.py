import base64
import os
import re
from textwrap import wrap
from typing import Dict, List, Union

import requests
import streamlit as st
import streamlit_mermaid as stmd  # Mermaid ì „ìš© ì»´í¬ë„ŒíŠ¸
from dotenv import load_dotenv
from langchain.chains.summarize import load_summarize_chain
from langchain.docstore.document import Document
from langchain.prompts import PromptTemplate
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_google_genai import ChatGoogleGenerativeAI
from notion_client import Client
from streamlit_local_storage import LocalStorage
from youtube_transcript_api import NoTranscriptFound, YouTubeTranscriptApi
from youtube_transcript_api.proxies import WebshareProxyConfig

# LocalStorage ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
localS = LocalStorage()

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” (ìŠ¤í¬ë¦½íŠ¸ ìµœìƒë‹¨)
if "notion_token" not in st.session_state:
    st.session_state.notion_token = localS.getItem("notion_token") or ""
if "notion_db_id" not in st.session_state:
    st.session_state.notion_db_id = localS.getItem("notion_db_id") or ""


# 1) .env íŒŒì¼ ë¡œë“œ
load_dotenv()


# 2) Streamlit ì„¸ì…˜ ìƒíƒœì— í”„ë¡ì‹œ ì •ë³´ ì´ˆê¸° ì €ì¥
if "proxy_username" not in st.session_state:
    st.session_state["proxy_username"] = os.getenv("WEBSHARE_PROXY_USERNAME")
    st.session_state["proxy_password"] = os.getenv("WEBSHARE_PROXY_PASSWORD")


def check_proxy_usage() -> None:
    """
    Webshare í”„ë¡ì‹œê°€ ì •ìƒ ì‘ë™í•˜ëŠ”ì§€ ê°„ë‹¨íˆ í™•ì¸í•©ë‹ˆë‹¤.
    httpbin.org/ip í˜¸ì¶œ ì‹œ ì‹¤ì œ ì™¸ë¶€ IPë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.
    """
    username = st.session_state.get("proxy_username")
    password = st.session_state.get("proxy_password")
    if not username or not password:
        st.write("ğŸ”— í”„ë¡ì‹œ ë¯¸ì„¤ì •: ì§ì ‘ ì—°ê²°ë¡œ ìš”ì²­í•©ë‹ˆë‹¤.")
        return

    proxy_host = "p.webshare.io"
    # 80, 1080, 3128 ì¤‘ í•˜ë‚˜ë¥¼ ì„ íƒ
    proxy_port = os.getenv("WEBSHARE_PROXY_PORT", "80")

    proxy_url = f"http://{username}:{password}@{proxy_host}:{proxy_port}"
    proxies = {
        "http": proxy_url,
        "https": proxy_url,  # HTTPSë„ ê°™ì€ í¬íŠ¸ë¡œ CONNECT
    }

    try:
        resp = requests.get("https://httpbin.org/ip", proxies=proxies, timeout=5)
        origin = resp.json().get("origin")
        st.write(f"ğŸ”’ í”„ë¡ì‹œ ì ìš©ë¨: ì¡°íšŒëœ IP â†’ {origin}")
    except Exception as e:
        st.write(f"âš ï¸ í”„ë¡ì‹œ IP ì¡°íšŒ ì‹¤íŒ¨: {e}")


# ë…¸ì…˜ DB ID ì¶”ì¶œ í•¨ìˆ˜
def extract_notion_database_id(notion_input: str) -> str:
    """
    Notion ì „ì²´ URL ë˜ëŠ” ìˆœìˆ˜ DB ì•„ì´ë””ì—ì„œ Database/Page IDë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
       ì…ë ¥ì´ ì´ë¯¸ 32ìë¦¬ 16ì§„ìˆ˜ IDë©´ ê·¸ëŒ€ë¡œ ë°˜í™˜í•˜ê³ , URLì´ë©´ ë§ˆì§€ë§‰ í•˜ì´í”ˆ ë’¤ IDë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.    ì˜ˆì‹œ: https://www.notion.so/sysmae/OSSW-01-GOATHUB-1d01566753468017b2a1ea7a7eccb17e
       ê²°ê³¼: 1d01566753468017b2a1ea7a7eccb17e
    """
    import re

    text = notion_input.strip()

    # 1) ìˆœìˆ˜ DB ì•„ì´ë””ì¸ì§€ í™•ì¸ (í•˜ì´í”ˆ ì œê±° í›„ 32ìë¦¬ 16ì§„ìˆ˜ ë§¤ì¹­)
    clean = text.replace("-", "")
    if re.fullmatch(r"[0-9a-fA-F]{32}", clean):
        return clean.lower()  # ì´ë¯¸ IDë©´ ê·¸ëŒ€ë¡œ ë°˜í™˜[2]

    # 2) URL í˜•íƒœì¼ ê²½ìš°, Notion URLì˜ ë§ˆì§€ë§‰ í•˜ì´í”ˆ ë’¤ 32ì(16ì§„ìˆ˜) ì¶”ì¶œ
    parts = text.split("-")
    if len(parts) > 1:
        candidate = parts[-1].replace("-", "")
        if re.fullmatch(r"[0-9a-fA-F]{32}", candidate):
            return candidate.lower()

    # 3) ì „ì²´ ë¬¸ìì—´ì—ì„œ 32ìë¦¬ 16ì§„ìˆ˜ íŒ¨í„´ íƒìƒ‰
    match = re.search(r"[0-9a-fA-F]{32}", text)
    if match:
        return match.group(0).lower()

    # ì‹¤íŒ¨ ì‹œ ë¹ˆ ë¬¸ìì—´ ë°˜í™˜
    return ""


# ìœ íŠœë¸Œ ë¹„ë””ì˜¤ ID ì¶”ì¶œ í•¨ìˆ˜
def extract_video_id(url):
    patterns = [
        r"(?:youtube\.com\/watch\?v=|youtu\.be\/|youtube\.com\/embed\/)([^&\n?#]+)",
        r"(?:youtube\.com\/shorts\/)([^&\n?#]+)",
    ]
    for pattern in patterns:
        match = re.search(pattern, url)
        if match:
            return match.group(1)
    return None


def get_transcript(
    video_id: str, languages: List[str] = None, fallback_enabled: bool = True
) -> List[Dict[str, Union[float, str]]]:
    """
    Webshare í”„ë¡ì‹œë¥¼ í™œìš©í•œ ìœ íŠœë¸Œ ëŒ€ë³¸ ì¶”ì¶œ í•¨ìˆ˜.
    ko, en ëŒ€ë³¸ì´ ì—†ìœ¼ë©´ ì‚¬ìš© ê°€ëŠ¥í•œ ì–¸ì–´ ë¦¬ìŠ¤íŠ¸ë¥¼ ì¡°íšŒí•´ ì¬ì‹œë„í•©ë‹ˆë‹¤.
    """
    # 1) ì–¸ì–´ ê¸°ë³¸ê°’ ì„¤ì •
    if languages is None:
        languages = ["ko", "en"]

    # 2) ì„¸ì…˜ ìƒíƒœì—ì„œ í”„ë¡ì‹œ ìê²©ì¦ëª… ì½ì–´ ì™€ Config ìƒì„±
    username = st.session_state.get("proxy_username")
    password = st.session_state.get("proxy_password")
    proxy_config = None
    if username and password:
        proxy_config = WebshareProxyConfig(proxy_username=username, proxy_password=password)

    # 3) Transcript API ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
    yt_api = YouTubeTranscriptApi(proxy_config=proxy_config)

    # 4) ìš°ì„  ìš”ì²­ ì–¸ì–´ë¡œ fetch ì‹œë„
    try:
        transcript = yt_api.fetch(video_id)
        return transcript.to_raw_data()
    except Exception:
        # 5) ko, en ë“± ìš”ì²­ ì–¸ì–´ê°€ ì—†ì„ ë•Œ ì‚¬ìš© ê°€ëŠ¥í•œ ì–¸ì–´ë¡œ ì¬ì‹œë„
        try:
            transcript_list = yt_api.list_transcripts(video_id)
            available_langs = [t.language_code for t in transcript_list]
            if not available_langs:
                raise ConnectionError("ëŒ€ë³¸ ì¶”ì¶œ ì‹¤íŒ¨: ì‚¬ìš© ê°€ëŠ¥í•œ ì–¸ì–´ ì—†ìŒ")
            return yt_api.fetch(video_id=video_id, languages=available_langs).to_raw_data()
        except Exception as e2:
            raise ConnectionError(f"ëŒ€ë³¸ ì¶”ì¶œ ì‹¤íŒ¨: {e2}") from e2


# LangChain ìš”ì•½ í•¨ìˆ˜ (Google GenAI ì‚¬ìš©)
def summarize_text(text):
    google_api_key = os.getenv("GOOGLE_API_KEY")
    if not google_api_key:
        return "GOOGLE_API_KEYê°€ .env íŒŒì¼ì— ì—†ìŠµë‹ˆë‹¤."
    # í…ìŠ¤íŠ¸ ë¶„í•  ì—†ì´ ì „ì²´ í…ìŠ¤íŠ¸ í•œ ë²ˆë§Œ ìš”ì•½
    prompt_template = """
# ğŸ“‘ ìœ íŠœë¸Œ ëŒ€ë³¸ì„ ê³„ì¸µì Â·ì‹œê°ì  Markdown ìš”ì•½ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” í”„ë¡¬í”„íŠ¸

## ğŸŸ¢ ëª©ì 
ìœ íŠœë¸Œ ì˜ìƒ ëŒ€ë³¸ì„ **ëª…í™•í•˜ê³  êµ¬ì¡°ì ì¸ ìš”ì•½**ìœ¼ë¡œ ì¬êµ¬ì„±í•©ë‹ˆë‹¤. ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ ì¶œë ¥í•˜ì„¸ìš”. ì•„ë˜ì˜ ìŠ¤íƒ€ì¼ ê°€ì´ë“œì™€ ì‘ì„± ê·œì¹™ì„ ë°˜ë“œì‹œ ì¤€ìˆ˜í•˜ì„¸ìš”.

---
## ğŸ“‹ í”„ë¡¬í”„íŠ¸ ì§€ì‹œì‚¬í•­

ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ ì•„ë˜ì˜ Markdown êµ¬ì¡°ë¡œ ìš”ì•½í•˜ì„¸ìš”.

### 1. êµ¬ì¡° ë° í¬ë§·
- **ìµœìƒìœ„ ì œëª©**: `#` + ì˜ìƒ í•µì‹¬ ì£¼ì œ (ì´ëª¨ì§€ í¬í•¨)
- **ì£¼ìš” ì„¹ì…˜**: `##` + ì´ëª¨ì§€ + í•µì‹¬ í‚¤ì›Œë“œ
- **í•˜ìœ„ í•­ëª©**: `###` + ë²ˆí˜¸. í‚¤ì›Œë“œ
- **ì„¸ë¶€ ë‚´ìš©**: ë¶ˆë¦¿í¬ì¸íŠ¸(â€“)ë¡œ ì •ë¦¬, í•„ìš”ì‹œ ì†Œì£¼ì œ ì¶”ê°€
- **ìµœì†Œ 3ë‹¨ê³„ ì´ìƒ ê³„ì¸µí™”**
- **ì¤‘ìš” ìš©ì–´ëŠ” êµµê²Œ, ìˆ˜ì¹˜/ì—°ë„/í•µì‹¬ ê²°ê³¼ëŠ” _ê¸°ìš¸ì„_ ì²˜ë¦¬**

### 2. ì‹œê°ì  ìš”ì†Œ
- ê° ì„¹ì…˜/í•­ëª©ì— ì–´ìš¸ë¦¬ëŠ” ì´ëª¨ì§€ í™œìš©
- í•„ìš” ì‹œ ê°„ë‹¨í•œ íë¦„ë„(flowchart) í˜•íƒœì˜ Mermaid ë‹¤ì´ì–´ê·¸ë¨ì„ Notion í˜¸í™˜ ê¸°ë³¸ ë¬¸ë²•ìœ¼ë¡œ ì‚½ì…
- Mermaid ì½”ë“œ ë¸”ë¡ì€ ë°˜ë“œì‹œ ì„¸ ê°œì˜ backtickê³¼ `mermaid` í‚¤ì›Œë“œë¡œ ê°ì‹¸ê¸°
- ë³µì¡í•œ ë¬¸ë²•ì€ ì‚¬ìš©í•˜ì§€ ì•Šê³ , ê¸°ë³¸ í˜•íƒœë¡œ ì œì‘
- í‘œ, ìˆœì„œë„, íƒ€ì„ë¼ì¸ ë“± Markdown ì§€ì› ìš”ì†Œ ì ê·¹ ì‚¬ìš©

### 3. ì„œìˆ  ìŠ¤íƒ€ì¼
- ê°ê´€ì Â·ì„¤ëª…ì²´, í•™ìˆ ì  í†¤
- ë¶ˆí•„ìš”í•œ ê°ìƒ/ì˜ê²¬/ê´‘ê³ ì„± ë¬¸êµ¬ ë°°ì œ
- í•µì‹¬ ì •ë³´ ìœ„ì£¼ë¡œ ê°„ê²°í•˜ê²Œ ì •ë¦¬
- ë™ì‚¬ëŠ” "~í•˜ì˜€ë‹¤" ë“± ê³¼ê±°í˜• ì‚¬ìš©

### 4. ì˜ˆì‹œ
# ğŸ’¡ í…ŒìŠ¬ë¼ì˜ ì„±ì¥ê³¼ ë„ì „
## 1. ğŸš— í…ŒìŠ¬ë¼ì˜ ì°½ë¦½ê³¼ ë¹„ì „
- **ì¼ë¡  ë¨¸ìŠ¤í¬**ê°€ *2003ë…„* í…ŒìŠ¬ë¼ ì„¤ë¦½ì— ì°¸ì—¬í•˜ì˜€ë‹¤.
- ì „ê¸°ì°¨ ëŒ€ì¤‘í™”ë¥¼ ëª©í‘œë¡œ í•˜ì˜€ë‹¤.
## 1.1. ì´ˆê¸° íˆ¬ìì™€ ê¸°ìˆ  ê°œë°œ
- *2008ë…„* ì²« ëª¨ë¸ **ë¡œë“œìŠ¤í„°** ì¶œì‹œ.
- ë°°í„°ë¦¬ ê¸°ìˆ  í˜ì‹ ì„ ì´ëŒì—ˆë‹¤.
## 2. ğŸ“ˆ ì‹œì¥ í™•ì¥ê³¼ ìƒì‚° ì „ëµ
- ê¸°ê°€íŒ©í† ë¦¬ ì„¤ë¦½ìœ¼ë¡œ ìƒì‚°ëŸ‰ì„ *3ë°°* ëŠ˜ë ¸ë‹¤.
- **ëª¨ë¸ 3** ì¶œì‹œë¡œ ëŒ€ì¤‘ ì‹œì¥ ì§„ì…ì— ì„±ê³µí•˜ì˜€ë‹¤.
`texttimeline
    2003 : ì°½ë¦½
    2008 : ë¡œë“œìŠ¤í„° ì¶œì‹œ
    2017 : ëª¨ë¸ 3 ì¶œì‹œ`
---

## ğŸŸ¨ ì£¼ì˜ì‚¬í•­
- ì˜ìƒ ëŒ€ë³¸ì˜ ëª¨ë“  ì£¼ìš” ë‚´ìš©ì„ ë¹ ì§ì—†ì´ êµ¬ì¡°ì ìœ¼ë¡œ í¬í•¨
- ì´ëª¨ì§€, ê³„ì¸µ êµ¬ì¡°, ì‹œê°í™” ìš”ì†Œ ë“±ì€ ë°˜ë“œì‹œ í¬í•¨
- ê´‘ê³ , ë¶ˆí•„ìš”í•œ ê°ìƒ, ì‚¬ì¡±ì€ ë°°ì œ

---
ì•„ë˜ ëŒ€ë³¸ì„ ìœ„ ê°€ì´ë“œì— ë”°ë¼ ìš”ì•½í•˜ì„¸ìš”.

{text}

ë§ˆí¬ë‹¤ìš´ í˜•ì‹ì˜ ìš”ì•½:
"""
    PROMPT = PromptTemplate(template=prompt_template, input_variables=["text"])
    llm = ChatGoogleGenerativeAI(
        model="gemini-2.0-flash", temperature=0, google_api_key=google_api_key
    )
    chain = load_summarize_chain(llm, chain_type="stuff", prompt=PROMPT, verbose=False)
    docs = [Document(page_content=text)]
    summary = chain.run(docs)
    return summary


# === ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” í•¨ìˆ˜ ===
def init_session():
    default_values = {
        "video_id": "",
        "transcript_text": "",
        "transcript_data": None,
        "summary": "",
        "summarize_clicked": False,
        "summarizing": False,
        "summarized": False,
        "auto_save_to_notion": True,  # ìë™ ì €ì¥ ê¸°ë³¸ê°’ True
        "notion_saved": False,
    }
    for k, v in default_values.items():
        if k not in st.session_state:
            st.session_state[k] = v


init_session()


# === ì˜ìƒ ë¡œë”© ë° ëŒ€ë³¸ ì¶”ì¶œ ===
def load_video(url):
    vid = extract_video_id(url)
    if not vid:
        st.error("ìœ íš¨í•˜ì§€ ì•Šì€ ìœ íŠœë¸Œ ë§í¬ì…ë‹ˆë‹¤.")
        return

    # ì˜ìƒ IDê°€ ë°”ë€ ê²½ìš°ì—ë§Œ ì—…ë°ì´íŠ¸
    if st.session_state.video_id != vid:
        data = get_transcript(vid)
        txt = " ".join([seg.get("text", "") for seg in data])

        if data:
            st.session_state.update(
                {
                    "video_id": vid,
                    "transcript_text": txt,
                    "transcript_data": data,
                    "summary": "",
                    "summarize_clicked": False,
                    "summarizing": False,
                    "summarized": False,
                    "notion_saved": False,
                }
            )
        else:
            st.error("ëŒ€ë³¸ ì¶”ì¶œ ì‹¤íŒ¨")


# === ìš”ì•½ ì‹¤í–‰ ===
def run_summary():
    with st.spinner("ìš”ì•½ ìƒì„± ì¤‘â€¦"):
        st.session_state.summary = summarize_text(st.session_state.transcript_text)
        st.session_state.summarize_clicked = True

        # âœ… ìë™ ì €ì¥ì´ ì¼œì ¸ ìˆìœ¼ë©´ ë°”ë¡œ Notion ì €ì¥
        if st.session_state.get("auto_save_to_notion") and not st.session_state.get(
            "notion_saved", False
        ):
            save_to_notion_as_page(st.session_state.summary)
            st.session_state["notion_saved"] = True


def render_summary():
    import re

    summary = st.session_state.summary

    if not summary:
        return

    with st.expander("ğŸ” ìš”ì•½ ê²°ê³¼ ë³´ê¸°", expanded=True):
        # 1. Mermaid ì½”ë“œ ë¸”ë¡ ì¶”ì¶œ ë° ë Œë”ë§ (ì‹œê°í™”ë§Œ)
        mermaid_blocks = re.findall(r"```mermaid\s+([\s\S]+?)```", summary)
        for code in mermaid_blocks:
            stmd.st_mermaid(code.strip())

        # 2. Mermaid ë¸”ë¡ ìì²´ëŠ” ë§ˆí¬ë‹¤ìš´ ì¶œë ¥ì—ì„œ ì œê±°
        cleaned = re.sub(r"```mermaid\s+[\s\S]+?```", "", summary)

        # 3. ë‚˜ë¨¸ì§€ ìš”ì•½ ë§ˆí¬ë‹¤ìš´ ì¶œë ¥
        st.markdown(cleaned, unsafe_allow_html=True)

    # 4. ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
    st.download_button(
        "ìš”ì•½ ë…¸íŠ¸ ë‹¤ìš´ë¡œë“œ",
        summary.encode(),
        f"summary_{st.session_state.video_id}.md",
        "text/markdown",
    )


def markdown_to_notion_blocks(markdown: str):
    """
    Markdown í…ìŠ¤íŠ¸ë¥¼ Notion ë¸”ë¡ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    - êµµì€ ê¸€ì”¨, ê¸°ìš¸ì„ ì ìš©
    - Mermaid ë¸”ë¡ì€ Notionì— ì €ì¥í•˜ì§€ ì•ŠìŒ
    """
    blocks = []
    lines = markdown.splitlines()

    in_code_block = False
    code_lang = ""
    code_lines = []

    def convert_text_to_rich(text):
        """êµµì€ ê¸€ì”¨ì™€ ê¸°ìš¸ì„ì„ Notion rich_text í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
        segments = []
        while text:
            bold = re.search(r"\*\*(.*?)\*\*", text)
            italic = re.search(r"_(.*?)_", text)
            if bold and (not italic or bold.start() < italic.start()):
                before = text[: bold.start()]
                if before:
                    segments.append({"type": "text", "text": {"content": before}})
                segments.append(
                    {
                        "type": "text",
                        "text": {"content": bold.group(1)},
                        "annotations": {"bold": True},
                    }
                )
                text = text[bold.end() :]
            elif italic:
                before = text[: italic.start()]
                if before:
                    segments.append({"type": "text", "text": {"content": before}})
                segments.append(
                    {
                        "type": "text",
                        "text": {"content": italic.group(1)},
                        "annotations": {"italic": True},
                    }
                )
                text = text[italic.end() :]
            else:
                segments.append({"type": "text", "text": {"content": text}})
                break
        return segments

    for line in lines:
        line = line.strip()

        if line.startswith("```"):
            if not in_code_block:
                in_code_block = True
                code_lang = line[3:].strip()
                code_lines = []
            else:
                # ì¢…ë£Œ ì‹œì 
                blocks.append(
                    {
                        "object": "block",
                        "type": "code",
                        "code": {
                            "language": code_lang or "plain text",
                            "rich_text": [
                                {"type": "text", "text": {"content": "\n".join(code_lines)}}
                            ],
                        },
                    }
                )
                in_code_block = False
        elif in_code_block:
            code_lines.append(line)
        elif line.startswith("# "):
            blocks.append(
                {
                    "object": "block",
                    "type": "heading_1",
                    "heading_1": {"rich_text": convert_text_to_rich(line[2:])},
                }
            )
        elif line.startswith("## "):
            blocks.append(
                {
                    "object": "block",
                    "type": "heading_2",
                    "heading_2": {"rich_text": convert_text_to_rich(line[3:])},
                }
            )
        elif line.startswith("### "):
            blocks.append(
                {
                    "object": "block",
                    "type": "heading_3",
                    "heading_3": {"rich_text": convert_text_to_rich(line[4:])},
                }
            )
        elif line.startswith("- "):
            blocks.append(
                {
                    "object": "block",
                    "type": "bulleted_list_item",
                    "bulleted_list_item": {"rich_text": convert_text_to_rich(line[2:])},
                }
            )
        elif line:
            blocks.append(
                {
                    "object": "block",
                    "type": "paragraph",
                    "paragraph": {"rich_text": convert_text_to_rich(line)},
                }
            )

    return blocks


def save_to_notion_as_page(summary: str):
    """
    Save the summary as a new page in Notion with proper formatting.
    """

    token = st.session_state.notion_token
    database_id = st.session_state.notion_db_id
    if not token or not database_id:
        st.error("Notion ì„¤ì •ì´ ì™„ë£Œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return False

    parent_database_id = database_id
    notion = Client(auth=token)

    try:
        # Split the summary into title and content
        lines = summary.strip().split("\n", 1)
        title = (
            lines[0][2:] if lines and lines[0].startswith("# ") else lines[0]
        )  # Remove leading '# '
        content = lines[1] if len(lines) > 1 else ""

        # Convert content to Notion blocks
        blocks = markdown_to_notion_blocks(content)
        blocks.append({"object": "block", "type": "divider", "divider": {}})

        # 2. ì œëª©: ì›ë³¸ ëŒ€ë³¸
        blocks.append(
            {
                "object": "block",
                "type": "heading_2",
                "heading_2": {"rich_text": [{"type": "text", "text": {"content": "ğŸ“œ ëŒ€ë³¸"}}]},
            }
        )

        # 3. ë³¸ë¬¸: ëŒ€ë³¸ í…ìŠ¤íŠ¸ë¥¼ ì ì ˆíˆ ë‚˜ëˆ ì„œ ë¸”ë¡ìœ¼ë¡œ ì¶”ê°€ (2000ì ì œí•œ íšŒí”¼)
        transcript_text = st.session_state.get("transcript_text", "")
        wrapped_segments = wrap(transcript_text, width=1800)

        for segment in wrapped_segments:
            blocks.append(
                {
                    "object": "block",
                    "type": "paragraph",
                    "paragraph": {"rich_text": [{"type": "text", "text": {"content": segment}}]},
                }
            )

        # Create a new page in Notion
        yt_url = st.session_state.get("yt_url", "")
        thumbnail_url = ""
        if yt_url:
            video_id = extract_video_id(yt_url)
            if video_id:
                thumbnail_url = f"https://img.youtube.com/vi/{video_id}/maxresdefault.jpg"

        # ì¸ë„¤ì¼ì´ ì—†ì„ ê²½ìš° ê¸°ë³¸ ì´ë¯¸ì§€ë¡œ ëŒ€ì²´ (Notionì´ í—ˆìš©í•˜ëŠ” ì™¸ë¶€ ì´ë¯¸ì§€ URL í•„ìš”)
        thumbnail_url = thumbnail_url or "https://via.placeholder.com/800x400?text=No+Thumbnail"

        notion.pages.create(
            parent={"type": "database_id", "database_id": parent_database_id},
            cover={"type": "external", "external": {"url": thumbnail_url or ""}},
            icon={"type": "emoji", "emoji": "ğŸ§ "},
            properties={
                "title": [
                    {
                        "type": "text",
                        "text": {"content": title},
                    }
                ]
            },
            children=blocks,  # ìœ„ì—ì„œ ì¶”ê°€ëœ ìš”ì•½ + ëŒ€ë³¸ í¬í•¨ëœ ì „ì²´ ë¸”ë¡
        )

        st.success("Summary has been saved as a new page in Notion!")
    except Exception as e:
        st.error(f"Error saving to Notion: {e}")


# === ë©”ì¸ ì•± ===
st.set_page_config(layout="wide", page_title="ìœ íŠœë¸Œ ëŒ€ë³¸ ìš”ì•½ ì„œë¹„ìŠ¤")
st.title("ìœ íŠœë¸Œ ëŒ€ë³¸ ìš”ì•½ ì„œë¹„ìŠ¤")

yt_url = st.text_input("ìœ íŠœë¸Œ ë§í¬ ì…ë ¥", placeholder="https://www.youtube.com/watch?v=...")
if yt_url:
    # ìœ íš¨í•œ ìœ íŠœë¸Œ IDë§Œ ìˆì„ ë•Œë§Œ load_video ì‹¤í–‰
    vid = extract_video_id(yt_url)
    st.session_state["yt_url"] = yt_url
    if vid:
        load_video(yt_url)
    else:
        st.error("ìœ íš¨í•˜ì§€ ì•Šì€ ìœ íŠœë¸Œ ë§í¬ì…ë‹ˆë‹¤.")

# === Notion ì„¤ì • ì…ë ¥ ===
with st.expander("âš™ï¸ Notion ì„¤ì • ì…ë ¥", expanded=False):
    # key ì—†ì´ ë°˜í™˜ê°’ë§Œ ë¡œì»¬ ë³€ìˆ˜ë¡œ ë°›ìœ¼ë©´ session_stateê°€ ì¦‰ì‹œ ë°”ë€Œì§€ ì•ŠìŒ
    input_token = st.text_input(
        "ğŸ”‘ Notion API Token",
        type="password",
        value=st.session_state.notion_token,
        placeholder="ntn_...",
    )
    input_db = st.text_input(
        "ğŸ“„ Notion Database URL OR ID",
        value=st.session_state.notion_db_id,
        placeholder="URL ë˜ëŠ” 32ìë¦¬ ID",
    )

    if st.button("âœ… OK - ì„¤ì • ì €ì¥"):
        token = input_token.strip()
        db_input = input_db.strip()

        if not token or not db_input:
            st.warning("âš ï¸ ëª¨ë“  í•„ë“œë¥¼ ì…ë ¥í•´ì•¼ í•©ë‹ˆë‹¤.")
        elif not re.match(r"^(ntn_|secret_)[A-Za-z0-9]+$", token):
            st.error("ğŸ”‘ Tokenì€ â€˜ntn_â€™ ë˜ëŠ” â€˜secret_â€™ìœ¼ë¡œ ì‹œì‘í•´ì•¼ í•©ë‹ˆë‹¤.")
        else:
            notion_db_id = extract_notion_database_id(db_input)
            if not notion_db_id:
                st.error("ğŸ“„ DB URL/ID í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            else:
                st.session_state.notion_token = token
                st.session_state.notion_db_id = notion_db_id
                localS.setItem("notion_token", token, key="set_notion_token")
                localS.setItem("notion_db_id", notion_db_id, key="set_notion_db_id")
                st.success("âœ… Notion ì„¤ì •ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

# === ìë™ ì €ì¥ í† ê¸€(ì‹¤ì‹œê°„ ë°˜ì˜) ===
st.session_state.auto_save_to_notion = st.checkbox(
    "âœ… ìš”ì•½ í›„ ìë™ Notion ì €ì¥",
    value=st.session_state.get("auto_save_to_notion", False),
    key="auto_save_toggle",
)

# === ìš”ì•½ ë° ëŒ€ë³¸ í‘œì‹œ ===
if st.session_state.transcript_data:
    col1, col2 = st.columns([2, 1])

    with col1:
        btn_placeholder = st.empty()
        if not st.session_state.summarize_clicked:
            if btn_placeholder.button("ëŒ€ë³¸ ìš”ì•½í•˜ê¸°"):
                btn_placeholder.empty()
                run_summary()

        render_summary()

    if st.session_state.get("summary"):
        # ìë™ ì €ì¥ í† ê¸€ì´ ì¼œì ¸ ìˆìœ¼ë©´ ìš”ì•½ ìƒì„± í›„ ë°”ë¡œ ì €ì¥
        if st.session_state.get("auto_save_to_notion") and not st.session_state.get(
            "notion_saved",
            False,
        ):
            save_to_notion_as_page(st.session_state["summary"])
            st.session_state["notion_saved"] = True
        elif not st.session_state.get("auto_save_to_notion"):
            if st.button("Save to Notion as Page"):
                save_to_notion_as_page(st.session_state["summary"])
                st.session_state["notion_saved"] = True

    with col2:
        st.subheader("ì›ë³¸ ëŒ€ë³¸")
        st.text_area("", st.session_state.transcript_text, height=300)
        if isinstance(st.session_state.transcript_data, list):
            with st.expander("ğŸ•’ íƒ€ì„ìŠ¤íƒ¬í”„ í¬í•¨ ëŒ€ë³¸", expanded=False):
                rows = []
                for e in st.session_state.transcript_data:
                    m, s = divmod(int(e.get("start", 0)), 60)
                    rows.append({"ì‹œê°„": f"{m:02d}:{s:02d}", "í…ìŠ¤íŠ¸": e.get("text", "")})
                st.dataframe(rows, height=200)
